.. _tbparse_parsing-hparams:

===================================
Parsing HParams
===================================

This page demonstrates the parsing process for hparams events.

.. contents:: Table of Contents
    :depth: 2
    :local:

Preparing Sample Event Logs
===================================

First, let's import some libraries and prepare the environment:

.. plot::
   :context: close-figs

   >>> import os
   >>> import tempfile
   >>> import pandas as pd
   >>> # Define some constants
   >>> N_RUNS = 3
   >>> N_EVENTS = 2
   >>> # Prepare temp dirs for storing event files
   >>> tmpdirs = {}

Before parsing a event file, we need to generate it first. The sample
event files are generated by three commonly used event log writers.

.. tabs::

   .. group-tab:: PyTorch

      We can generate the events by
      `PyTorch <https://pytorch.org/docs/stable/tensorboard.html>`_:

      .. plot::
         :context: close-figs

         >>> tmpdirs['torch'] = tempfile.TemporaryDirectory()
         >>> from torch.utils.tensorboard import SummaryWriter
         >>> log_dir = tmpdirs['torch'].name
         >>> for i in range(N_RUNS): # 3 independent runs
         ...   writer = SummaryWriter(os.path.join(log_dir, f'run{i}'))
         ...   writer.add_hparams({
         ...      'name': f'y=2x+{i}',
         ...      'run_id': i,
         ...      'C': i
         ...   }, {'metric': i}, run_name='.')
         ...   for j in range(N_EVENTS): # 2 events
         ...     writer.add_scalar('y=2x+C', j * 2 + i, j)
         ...   writer.close()

      and quickly check the results:

         >>> from tbparse import SummaryReader
         >>> SummaryReader(log_dir, pivot=True, extra_columns={'dir_name'}).scalars
            step  metric  y=2x+C dir_name
         0     0     0.0     0.0     run0
         1     1     NaN     2.0     run0
         2     0     1.0     1.0     run1
         3     1     NaN     3.0     run1
         4     0     2.0     2.0     run2
         5     1     NaN     4.0     run2
         >>> SummaryReader(log_dir, pivot=True, extra_columns={'dir_name'}).hparams
              C    name  run_id dir_name
         0  0.0  y=2x+0     0.0     run0
         1  1.0  y=2x+1     1.0     run1
         2  2.0  y=2x+2     2.0     run2

   .. group-tab:: TensorFlow / Keras

      We can generate the events by
      `TensorFlow / Keras <https://www.tensorflow.org/tensorboard/get_started>`_:

      .. plot::
         :context: close-figs

         >>> tmpdirs['tensorflow'] = tempfile.TemporaryDirectory()
         >>> import tensorflow as tf
         >>> from tensorboard.plugins.hparams import api as hp
         >>> log_dir = tmpdirs['tensorflow'].name
         >>> for i in range(N_RUNS): # 3 independent runs
         ...   writer = tf.summary.create_file_writer(os.path.join(log_dir, f'run{i}'))
         ...   writer.set_as_default()
         ...   assert hp.hparams({
         ...      'name': f'y=2x+{i}',
         ...      'run_id': i,
         ...      'C': i
         ...   })
         ...   assert tf.summary.scalar('metric', i, step=0)
         ...   for j in range(N_EVENTS): # 2 events
         ...     assert tf.summary.scalar('y=2x+C', j * 2 + i, j)
         ...   writer.close()

      and quickly check the results:

         >>> from tbparse import SummaryReader
         >>> SummaryReader(log_dir, pivot=True, extra_columns={'dir_name'}).tensors
            step  metric  y=2x+C dir_name
         0     0     0.0     0.0     run0
         1     1     NaN     2.0     run0
         2     0     1.0     1.0     run1
         3     1     NaN     3.0     run1
         4     0     2.0     2.0     run2
         5     1     NaN     4.0     run2
         >>> SummaryReader(log_dir, pivot=True, extra_columns={'dir_name'}).hparams
              C    name  run_id dir_name
         0  0.0  y=2x+0     0.0     run0
         1  1.0  y=2x+1     1.0     run1
         2  2.0  y=2x+2     2.0     run2

   .. group-tab:: TensorboardX

      We can generate the events by
      `TensorboardX <https://tensorboardx.readthedocs.io/en/latest/tutorial.html>`_:

      .. plot::
         :context: close-figs

         >>> tmpdirs['tensorboardX'] = tempfile.TemporaryDirectory()
         >>> from tensorboardX import SummaryWriter
         >>> log_dir = tmpdirs['tensorboardX'].name
         >>> for i in range(N_RUNS): # 3 independent runs
         ...   writer = SummaryWriter(os.path.join(log_dir, f'run{i}'))
         ...   event_filepath = writer.file_writer.event_writer._ev_writer._file_name
         ...   event_filename = os.path.basename(event_filepath)
         ...   writer.add_hparams({
         ...      'name': f'y=2x+{i}',
         ...      'run_id': i,
         ...      'C': i
         ...   }, {'metric': i}, name='hp')
         ...   for j in range(N_EVENTS): # 2 events
         ...     writer.add_scalar('y=2x+C', j * 2 + i, j)
         ...   writer.close()

      and quickly check the results:

         >>> from tbparse import SummaryReader
         >>> SummaryReader(log_dir, pivot=True, extra_columns={'dir_name'}).scalars
            step  metric  y_2x_C dir_name
         0     0     NaN     0.0     run0
         1     1     NaN     2.0     run0
         2     0     0.0     NaN  run0/hp
         3     0     NaN     1.0     run1
         4     1     NaN     3.0     run1
         5     0     1.0     NaN  run1/hp
         6     0     NaN     2.0     run2
         7     1     NaN     4.0     run2
         8     0     2.0     NaN  run2/hp
         >>> SummaryReader(log_dir, pivot=True, extra_columns={'dir_name'}).hparams
              C    name  run_id dir_name
         0  0.0  y=2x+0     0.0  run0/hp
         1  1.0  y=2x+1     1.0  run1/hp
         2  2.0  y=2x+2     2.0  run2/hp

      .. WARNING:: TensorboardX automatically escapes special character ``=``, ``+`` in the
         specified tags.

.. Note:: This tutorial assumes you only log a set of HParams under each run directory.

Parsing Event Logs
===================================

Import the :class:`tbparse.SummaryReader` class and prepare the log file paths
for reading event logs.

In the following samples, we use the event files generated by PyTorch for
simplicity. Event files generated by TensorboardX and TensorFlow can be
similarily parsed with minor modifications.

.. plot::
   :context: close-figs

   >>> from tbparse import SummaryReader
   >>> log_dir = tmpdirs['torch'].name
   >>> run_dir = os.path.join(log_dir, 'run0')
   >>> event_file = os.path.join(run_dir, sorted(os.listdir(run_dir))[0])

Now we load the event logs as :class:`pandas.DataFrame`.

.. tabs::

   .. group-tab:: Long Format

      >>> reader = SummaryReader(log_dir, extra_columns={'dir_name'}) # long format
      >>> reader.hparams
            tag   value dir_name
      0       C     0.0     run0
      1    name  y=2x+0     run0
      2  run_id     0.0     run0
      3       C     1.0     run1
      4    name  y=2x+1     run1
      5  run_id     1.0     run1
      6       C     2.0     run2
      7    name  y=2x+2     run2
      8  run_id     2.0     run2

   .. group-tab:: Wide Format

      >>> reader = SummaryReader(log_dir, pivot=True, extra_columns={'dir_name'}) # wide format
      >>> reader.hparams
           C    name  run_id dir_name
      0  0.0  y=2x+0     0.0     run0
      1  1.0  y=2x+1     1.0     run1
      2  2.0  y=2x+2     2.0     run2

Filtering Events Based on HParams
===================================

    TensorBoard reads data from a full directory, and organizes it into the
    history of a single TensorFlow execution.

    -- `Tensorboard GitHub README <https://github.com/tensorflow/tensorboard#event-files--logdirs-how-tensorboard-loads-the-data>`_

Since tensorboard considers all event files under a run directory as the same run,
we can filter out irrelevant events based on the HParams stored under the run directory.

Filtering Events with a Single Criterion
----------------------------------------------------------------------

Assume we want to keep events with HParams ``C == 0.0``.

.. tabs::

   .. group-tab:: Long/Long

      >>> # filter long scalars with long hparams
      >>> reader = SummaryReader(log_dir, extra_columns={'dir_name'}) # long format
      >>> hp = reader.hparams
      >>> hp
            tag   value dir_name
      0       C     0.0     run0
      1    name  y=2x+0     run0
      2  run_id     0.0     run0
      3       C     1.0     run1
      4    name  y=2x+1     run1
      5  run_id     1.0     run1
      6       C     2.0     run2
      7    name  y=2x+2     run2
      8  run_id     2.0     run2
      >>> hp_filtered = hp[(hp['tag']=='C') & (hp['value']==0.0)]
      >>> hp_filtered
        tag value dir_name
      0   C   0.0     run0
      >>> run_names = list(hp_filtered['dir_name'])
      >>> run_names
      ['run0']
      >>> df = reader.scalars
      >>> df
         step     tag  value dir_name
      0     0  metric    0.0     run0
      1     0  y=2x+C    0.0     run0
      2     1  y=2x+C    2.0     run0
      3     0  metric    1.0     run1
      4     0  y=2x+C    1.0     run1
      5     1  y=2x+C    3.0     run1
      6     0  metric    2.0     run2
      7     0  y=2x+C    2.0     run2
      8     1  y=2x+C    4.0     run2
      >>> df_filtered = df[df['dir_name'].isin(run_names)]
      >>> df_filtered
         step     tag  value dir_name
      0     0  metric    0.0     run0
      1     0  y=2x+C    0.0     run0
      2     1  y=2x+C    2.0     run0

   .. group-tab:: Wide/Wide

      >>> # filter wide scalars with wide hparams
      >>> reader = SummaryReader(log_dir, pivot=True, extra_columns={'dir_name'}) # wide format
      >>> hp = reader.hparams
      >>> hp
           C    name  run_id dir_name
      0  0.0  y=2x+0     0.0     run0
      1  1.0  y=2x+1     1.0     run1
      2  2.0  y=2x+2     2.0     run2
      >>> hp_filtered = hp[hp['C']==0.0]
      >>> hp_filtered
           C    name  run_id dir_name
      0  0.0  y=2x+0     0.0     run0
      >>> run_names = list(hp_filtered['dir_name'])
      >>> run_names
      ['run0']
      >>> df = reader.scalars
      >>> df
         step  metric  y=2x+C dir_name
      0     0     0.0     0.0     run0
      1     1     NaN     2.0     run0
      2     0     1.0     1.0     run1
      3     1     NaN     3.0     run1
      4     0     2.0     2.0     run2
      5     1     NaN     4.0     run2
      >>> df_filtered = df[df['dir_name'].isin(run_names)]
      >>> df_filtered
         step  metric  y=2x+C dir_name
      0     0     0.0     0.0     run0
      1     1     NaN     2.0     run0

   .. group-tab:: Long/Wide

      >>> # filter long scalars with wide hparams
      >>> reader = SummaryReader(log_dir, pivot=True, extra_columns={'dir_name'}) # wide format
      >>> hp = reader.hparams
      >>> hp
           C    name  run_id dir_name
      0  0.0  y=2x+0     0.0     run0
      1  1.0  y=2x+1     1.0     run1
      2  2.0  y=2x+2     2.0     run2
      >>> hp_filtered = hp[hp['C']==0.0]
      >>> hp_filtered
           C    name  run_id dir_name
      0  0.0  y=2x+0     0.0     run0
      >>> run_names = list(hp_filtered['dir_name'])
      >>> run_names
      ['run0']
      >>> reader = SummaryReader(log_dir, extra_columns={'dir_name'}) # long format
      >>> df = reader.scalars
      >>> df
         step     tag  value dir_name
      0     0  metric    0.0     run0
      1     0  y=2x+C    0.0     run0
      2     1  y=2x+C    2.0     run0
      3     0  metric    1.0     run1
      4     0  y=2x+C    1.0     run1
      5     1  y=2x+C    3.0     run1
      6     0  metric    2.0     run2
      7     0  y=2x+C    2.0     run2
      8     1  y=2x+C    4.0     run2
      >>> df_filtered = df[df['dir_name'].isin(run_names)]
      >>> df_filtered
         step     tag  value dir_name
      0     0  metric    0.0     run0
      1     0  y=2x+C    0.0     run0
      2     1  y=2x+C    2.0     run0

   .. group-tab:: Wide/Long

      >>> # filter wide scalars with long hparams
      >>> reader = SummaryReader(log_dir, extra_columns={'dir_name'}) # long format
      >>> hp = reader.hparams
      >>> hp
            tag   value dir_name
      0       C     0.0     run0
      1    name  y=2x+0     run0
      2  run_id     0.0     run0
      3       C     1.0     run1
      4    name  y=2x+1     run1
      5  run_id     1.0     run1
      6       C     2.0     run2
      7    name  y=2x+2     run2
      8  run_id     2.0     run2
      >>> hp_filtered = hp[(hp['tag']=='C') & (hp['value']==0.0)]
      >>> hp_filtered
        tag value dir_name
      0   C   0.0     run0
      >>> run_names = list(hp_filtered['dir_name'])
      >>> run_names
      ['run0']
      >>> reader = SummaryReader(log_dir, pivot=True, extra_columns={'dir_name'}) # wide format
      >>> df = reader.scalars
      >>> df
         step  metric  y=2x+C dir_name
      0     0     0.0     0.0     run0
      1     1     NaN     2.0     run0
      2     0     1.0     1.0     run1
      3     1     NaN     3.0     run1
      4     0     2.0     2.0     run2
      5     1     NaN     4.0     run2
      >>> df_filtered = df[df['dir_name'].isin(run_names)]
      >>> df_filtered
         step  metric  y=2x+C dir_name
      0     0     0.0     0.0     run0
      1     1     NaN     2.0     run0

Filtering Events with Multiple Criteria
----------------------------------------------------------------------

Assume we want to keep events with HParams ``C == 0.0`` or ``name == 'y=2x+2'``.

.. tabs::

   .. group-tab:: Long/Long

      >>> # filter long scalars with long hparams
      >>> reader = SummaryReader(log_dir, extra_columns={'dir_name'}) # long format
      >>> hp = reader.hparams
      >>> hp
            tag   value dir_name
      0       C     0.0     run0
      1    name  y=2x+0     run0
      2  run_id     0.0     run0
      3       C     1.0     run1
      4    name  y=2x+1     run1
      5  run_id     1.0     run1
      6       C     2.0     run2
      7    name  y=2x+2     run2
      8  run_id     2.0     run2
      >>> cond1 = (hp['tag']=='C') & (hp['value']==0.0)
      >>> cond2 = (hp['tag']=='name') & (hp['value']=='y=2x+2')
      >>> hp_filtered = hp[cond1 | cond2]
      >>> hp_filtered
          tag   value dir_name
      0     C     0.0     run0
      7  name  y=2x+2     run2
      >>> run_names = list(hp_filtered['dir_name'])
      >>> run_names
      ['run0', 'run2']
      >>> df = reader.scalars
      >>> df
         step     tag  value dir_name
      0     0  metric    0.0     run0
      1     0  y=2x+C    0.0     run0
      2     1  y=2x+C    2.0     run0
      3     0  metric    1.0     run1
      4     0  y=2x+C    1.0     run1
      5     1  y=2x+C    3.0     run1
      6     0  metric    2.0     run2
      7     0  y=2x+C    2.0     run2
      8     1  y=2x+C    4.0     run2
      >>> df_filtered = df[df['dir_name'].isin(run_names)]
      >>> df_filtered
         step     tag  value dir_name
      0     0  metric    0.0     run0
      1     0  y=2x+C    0.0     run0
      2     1  y=2x+C    2.0     run0
      6     0  metric    2.0     run2
      7     0  y=2x+C    2.0     run2
      8     1  y=2x+C    4.0     run2

   .. group-tab:: Wide/Wide

      >>> # filter wide scalars with wide hparams
      >>> reader = SummaryReader(log_dir, pivot=True, extra_columns={'dir_name'}) # wide format
      >>> hp = reader.hparams
      >>> hp
           C    name  run_id dir_name
      0  0.0  y=2x+0     0.0     run0
      1  1.0  y=2x+1     1.0     run1
      2  2.0  y=2x+2     2.0     run2
      >>> hp_filtered = hp[(hp['C']==0.0) | (hp['name']=='y=2x+2')]
      >>> hp_filtered
           C    name  run_id dir_name
      0  0.0  y=2x+0     0.0     run0
      2  2.0  y=2x+2     2.0     run2
      >>> run_names = list(hp_filtered['dir_name'])
      >>> run_names
      ['run0', 'run2']
      >>> df = reader.scalars
      >>> df
         step  metric  y=2x+C dir_name
      0     0     0.0     0.0     run0
      1     1     NaN     2.0     run0
      2     0     1.0     1.0     run1
      3     1     NaN     3.0     run1
      4     0     2.0     2.0     run2
      5     1     NaN     4.0     run2
      >>> df_filtered = df[df['dir_name'].isin(run_names)]
      >>> df_filtered
         step  metric  y=2x+C dir_name
      0     0     0.0     0.0     run0
      1     1     NaN     2.0     run0
      4     0     2.0     2.0     run2
      5     1     NaN     4.0     run2

   .. group-tab:: Long/Wide

      >>> # filter long scalars with wide hparams
      >>> reader = SummaryReader(log_dir, pivot=True, extra_columns={'dir_name'}) # wide format
      >>> hp = reader.hparams
      >>> hp
           C    name  run_id dir_name
      0  0.0  y=2x+0     0.0     run0
      1  1.0  y=2x+1     1.0     run1
      2  2.0  y=2x+2     2.0     run2
      >>> hp_filtered = hp[(hp['C']==0.0) | (hp['name']=='y=2x+2')]
      >>> hp_filtered
           C    name  run_id dir_name
      0  0.0  y=2x+0     0.0     run0
      2  2.0  y=2x+2     2.0     run2
      >>> run_names = list(hp_filtered['dir_name'])
      >>> run_names
      ['run0', 'run2']
      >>> reader = SummaryReader(log_dir, extra_columns={'dir_name'}) # long format
      >>> df = reader.scalars
      >>> df
         step     tag  value dir_name
      0     0  metric    0.0     run0
      1     0  y=2x+C    0.0     run0
      2     1  y=2x+C    2.0     run0
      3     0  metric    1.0     run1
      4     0  y=2x+C    1.0     run1
      5     1  y=2x+C    3.0     run1
      6     0  metric    2.0     run2
      7     0  y=2x+C    2.0     run2
      8     1  y=2x+C    4.0     run2
      >>> df_filtered = df[df['dir_name'].isin(run_names)]
      >>> df_filtered
         step     tag  value dir_name
      0     0  metric    0.0     run0
      1     0  y=2x+C    0.0     run0
      2     1  y=2x+C    2.0     run0
      6     0  metric    2.0     run2
      7     0  y=2x+C    2.0     run2
      8     1  y=2x+C    4.0     run2

   .. group-tab:: Wide/Long

      >>> # filter wide scalars with long hparams
      >>> reader = SummaryReader(log_dir, extra_columns={'dir_name'}) # long format
      >>> hp = reader.hparams
      >>> hp
            tag   value dir_name
      0       C     0.0     run0
      1    name  y=2x+0     run0
      2  run_id     0.0     run0
      3       C     1.0     run1
      4    name  y=2x+1     run1
      5  run_id     1.0     run1
      6       C     2.0     run2
      7    name  y=2x+2     run2
      8  run_id     2.0     run2
      >>> cond1 = (hp['tag']=='C') & (hp['value']==0.0)
      >>> cond2 = (hp['tag']=='name') & (hp['value']=='y=2x+2')
      >>> hp_filtered = hp[cond1 | cond2]
      >>> hp_filtered
          tag   value dir_name
      0     C     0.0     run0
      7  name  y=2x+2     run2
      >>> run_names = list(hp_filtered['dir_name'])
      >>> run_names
      ['run0', 'run2']
      >>> reader = SummaryReader(log_dir, pivot=True, extra_columns={'dir_name'}) # wide format
      >>> df = reader.scalars
      >>> df
         step  metric  y=2x+C dir_name
      0     0     0.0     0.0     run0
      1     1     NaN     2.0     run0
      2     0     1.0     1.0     run1
      3     1     NaN     3.0     run1
      4     0     2.0     2.0     run2
      5     1     NaN     4.0     run2
      >>> df_filtered = df[df['dir_name'].isin(run_names)]
      >>> df_filtered
         step  metric  y=2x+C dir_name
      0     0     0.0     0.0     run0
      1     1     NaN     2.0     run0
      4     0     2.0     2.0     run2
      5     1     NaN     4.0     run2

Store Filtering Results in an Additional Column
----------------------------------------------------------------------

Assume we want to store the name in HParams to an additional column in the scalars DataFrame.

.. tabs::

   .. group-tab:: Long/Long

      >>> # filter long scalars with long hparams
      >>> reader = SummaryReader(log_dir, extra_columns={'dir_name'}) # long format
      >>> hp = reader.hparams
      >>> hp
            tag   value dir_name
      0       C     0.0     run0
      1    name  y=2x+0     run0
      2  run_id     0.0     run0
      3       C     1.0     run1
      4    name  y=2x+1     run1
      5  run_id     1.0     run1
      6       C     2.0     run2
      7    name  y=2x+2     run2
      8  run_id     2.0     run2
      >>> hp_filtered = hp[hp['tag']=='name']
      >>> hp_filtered.set_index('dir_name', inplace=True)
      >>> run_to_name = hp_filtered.to_dict()['value']
      >>> run_to_name
      {'run0': 'y=2x+0', 'run1': 'y=2x+1', 'run2': 'y=2x+2'}
      >>> df = reader.scalars
      >>> df
         step     tag  value dir_name
      0     0  metric    0.0     run0
      1     0  y=2x+C    0.0     run0
      2     1  y=2x+C    2.0     run0
      3     0  metric    1.0     run1
      4     0  y=2x+C    1.0     run1
      5     1  y=2x+C    3.0     run1
      6     0  metric    2.0     run2
      7     0  y=2x+C    2.0     run2
      8     1  y=2x+C    4.0     run2
      >>> df['hp/name'] = df['dir_name'].map(run_to_name)
      >>> df
         step     tag  value dir_name hp/name
      0     0  metric    0.0     run0  y=2x+0
      1     0  y=2x+C    0.0     run0  y=2x+0
      2     1  y=2x+C    2.0     run0  y=2x+0
      3     0  metric    1.0     run1  y=2x+1
      4     0  y=2x+C    1.0     run1  y=2x+1
      5     1  y=2x+C    3.0     run1  y=2x+1
      6     0  metric    2.0     run2  y=2x+2
      7     0  y=2x+C    2.0     run2  y=2x+2
      8     1  y=2x+C    4.0     run2  y=2x+2

   .. group-tab:: Wide/Wide

      >>> # filter wide scalars with wide hparams
      >>> reader = SummaryReader(log_dir, pivot=True, extra_columns={'dir_name'}) # wide format
      >>> hp = reader.hparams
      >>> hp
           C    name  run_id dir_name
      0  0.0  y=2x+0     0.0     run0
      1  1.0  y=2x+1     1.0     run1
      2  2.0  y=2x+2     2.0     run2
      >>> hp_filtered = hp[['name', 'dir_name']]
      >>> hp_filtered.set_index('dir_name', inplace=True)
      >>> run_to_name = hp_filtered.to_dict()['name']
      >>> run_to_name
      {'run0': 'y=2x+0', 'run1': 'y=2x+1', 'run2': 'y=2x+2'}
      >>> df = reader.scalars
      >>> df
         step  metric  y=2x+C dir_name
      0     0     0.0     0.0     run0
      1     1     NaN     2.0     run0
      2     0     1.0     1.0     run1
      3     1     NaN     3.0     run1
      4     0     2.0     2.0     run2
      5     1     NaN     4.0     run2
      >>> df['hp/name'] = df['dir_name'].map(run_to_name)
      >>> df
         step  metric  y=2x+C dir_name hp/name
      0     0     0.0     0.0     run0  y=2x+0
      1     1     NaN     2.0     run0  y=2x+0
      2     0     1.0     1.0     run1  y=2x+1
      3     1     NaN     3.0     run1  y=2x+1
      4     0     2.0     2.0     run2  y=2x+2
      5     1     NaN     4.0     run2  y=2x+2

   .. group-tab:: Long/Wide

      >>> # filter long scalars with wide hparams
      >>> reader = SummaryReader(log_dir, pivot=True, extra_columns={'dir_name'}) # wide format
      >>> hp = reader.hparams
      >>> hp
           C    name  run_id dir_name
      0  0.0  y=2x+0     0.0     run0
      1  1.0  y=2x+1     1.0     run1
      2  2.0  y=2x+2     2.0     run2
      >>> hp_filtered = hp[['name', 'dir_name']]
      >>> hp_filtered.set_index('dir_name', inplace=True)
      >>> run_to_name = hp_filtered.to_dict()['name']
      >>> run_to_name
      {'run0': 'y=2x+0', 'run1': 'y=2x+1', 'run2': 'y=2x+2'}
      >>> reader = SummaryReader(log_dir, extra_columns={'dir_name'}) # long format
      >>> df = reader.scalars
      >>> df
         step     tag  value dir_name
      0     0  metric    0.0     run0
      1     0  y=2x+C    0.0     run0
      2     1  y=2x+C    2.0     run0
      3     0  metric    1.0     run1
      4     0  y=2x+C    1.0     run1
      5     1  y=2x+C    3.0     run1
      6     0  metric    2.0     run2
      7     0  y=2x+C    2.0     run2
      8     1  y=2x+C    4.0     run2
      >>> df['hp/name'] = df['dir_name'].map(run_to_name)
      >>> df
         step     tag  value dir_name hp/name
      0     0  metric    0.0     run0  y=2x+0
      1     0  y=2x+C    0.0     run0  y=2x+0
      2     1  y=2x+C    2.0     run0  y=2x+0
      3     0  metric    1.0     run1  y=2x+1
      4     0  y=2x+C    1.0     run1  y=2x+1
      5     1  y=2x+C    3.0     run1  y=2x+1
      6     0  metric    2.0     run2  y=2x+2
      7     0  y=2x+C    2.0     run2  y=2x+2
      8     1  y=2x+C    4.0     run2  y=2x+2

   .. group-tab:: Wide/Long

      >>> # filter wide scalars with long hparams
      >>> reader = SummaryReader(log_dir, extra_columns={'dir_name'}) # long format
      >>> hp = reader.hparams
      >>> hp
            tag   value dir_name
      0       C     0.0     run0
      1    name  y=2x+0     run0
      2  run_id     0.0     run0
      3       C     1.0     run1
      4    name  y=2x+1     run1
      5  run_id     1.0     run1
      6       C     2.0     run2
      7    name  y=2x+2     run2
      8  run_id     2.0     run2
      >>> hp_filtered = hp[hp['tag']=='name']
      >>> hp_filtered.set_index('dir_name', inplace=True)
      >>> run_to_name = hp_filtered.to_dict()['value']
      >>> run_to_name
      {'run0': 'y=2x+0', 'run1': 'y=2x+1', 'run2': 'y=2x+2'}
      >>> reader = SummaryReader(log_dir, pivot=True, extra_columns={'dir_name'}) # wide format
      >>> df = reader.scalars
      >>> df
         step  metric  y=2x+C dir_name
      0     0     0.0     0.0     run0
      1     1     NaN     2.0     run0
      2     0     1.0     1.0     run1
      3     1     NaN     3.0     run1
      4     0     2.0     2.0     run2
      5     1     NaN     4.0     run2
      >>> df['hp/name'] = df['dir_name'].map(run_to_name)
      >>> df
         step  metric  y=2x+C dir_name hp/name
      0     0     0.0     0.0     run0  y=2x+0
      1     1     NaN     2.0     run0  y=2x+0
      2     0     1.0     1.0     run1  y=2x+1
      3     1     NaN     3.0     run1  y=2x+1
      4     0     2.0     2.0     run2  y=2x+2
      5     1     NaN     4.0     run2  y=2x+2

Storing Hierarchical HParams
===================================

Tensorboard only allows logging ``bool``, ``float``, ``int``, ``str`` data.
For hierarchical data, we can serialize other types into json string for later use.

   >>> import json
   >>> def flatten_dict(hp):
   ...   d = {}
   ...   for key in hp.keys():
   ...     value = hp[key]
   ...     if not isinstance(value, (bool, float, int, str)):
   ...       value = json.dumps(value)
   ...     d[key] = value
   ...   return d

.. tabs::

   .. group-tab:: PyTorch

         >>> tmpdirs['torch'] = tempfile.TemporaryDirectory()
         >>> from torch.utils.tensorboard import SummaryWriter
         >>> log_dir = tmpdirs['torch'].name
         >>> hp_dict = {
         ...   'name': 'hp_name',
         ...   'hierarchical': {'run_id': 0}
         ... }
         >>> writer = SummaryWriter(os.path.join(log_dir, 'run0'))
         >>> writer.add_hparams(flatten_dict(hp_dict), {}, run_name='.')
         >>> writer.close()

      and quickly check the results:

         >>> from tbparse import SummaryReader
         >>> SummaryReader(log_dir, pivot=True, extra_columns={'dir_name'}).hparams
             hierarchical     name dir_name
         0  {"run_id": 0}  hp_name     run0

   .. group-tab:: TensorFlow / Keras

         >>> tmpdirs['tensorflow'] = tempfile.TemporaryDirectory()
         >>> import tensorflow as tf
         >>> from tensorboard.plugins.hparams import api as hp
         >>> log_dir = tmpdirs['tensorflow'].name
         >>> hp_dict = {
         ...   'name': 'hp_name',
         ...   'hierarchical': {'run_id': 0}
         ... }
         >>> writer = tf.summary.create_file_writer(os.path.join(log_dir, 'run0'))
         >>> writer.set_as_default()
         >>> assert hp.hparams(flatten_dict(hp_dict))
         >>> writer.close()

      and quickly check the results:

         >>> from tbparse import SummaryReader
         >>> SummaryReader(log_dir, pivot=True, extra_columns={'dir_name'}).hparams
             hierarchical     name dir_name
         0  {"run_id": 0}  hp_name     run0

   .. group-tab:: TensorboardX

         >>> tmpdirs['tensorboardX'] = tempfile.TemporaryDirectory()
         >>> from tensorboardX import SummaryWriter
         >>> log_dir = tmpdirs['tensorboardX'].name
         >>> hp_dict = {
         ...   'name': 'hp_name',
         ...   'hierarchical': {'run_id': 0}
         ... }
         >>> writer = SummaryWriter(os.path.join(log_dir, 'run0'))
         >>> writer.add_hparams(flatten_dict(hp_dict), {}, name='hp')
         >>> writer.close()

      and quickly check the results:

         >>> from tbparse import SummaryReader
         >>> SummaryReader(log_dir, pivot=True, extra_columns={'dir_name'}).hparams
             hierarchical     name dir_name
         0  {"run_id": 0}  hp_name  run0/hp

      .. WARNING:: TensorboardX automatically escapes special character ``=``, ``+`` in the
         specified tags.